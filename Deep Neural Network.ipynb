{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "[[ 0.00505119]\n",
      " [ 0.00505119]\n",
      " [ 0.99494905]\n",
      " [ 0.99494905]]\n"
     ]
    }
   ],
   "source": [
    "# No hidden layer\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "def sigmoid_to_derivative(output):\n",
    "    return output*(1 - output)\n",
    "\n",
    "# Create input - (4x2)\n",
    "X = np.array([[0,1],\n",
    "             [0,1],\n",
    "             [1,0],\n",
    "             [1,0]])\n",
    "\n",
    "# Create output - (4x1)\n",
    "y = np.array([[0],\n",
    "              [0],\n",
    "              [1],\n",
    "              [1]])\n",
    "\n",
    "# Seed random number so that it won't change when re-run.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Initialize weights (from -1 to 1) (2x1)\n",
    "weights_0 = 2 * np.random.random((2,1)) - 1\n",
    "\n",
    "for i in range(10000):\n",
    "    # Forward propagation\n",
    "    layer_0 = X\n",
    "    layer_1 = sigmoid(np.dot(layer_0,weights_0))\n",
    "    \n",
    "    # Error\n",
    "    layer_1_error = layer_1 - y\n",
    "    \n",
    "    # Back propagation = error * derivative(output)\n",
    "    layer_1_delta = layer_1_error * sigmoid_to_derivative(layer_1)\n",
    "    \n",
    "    # Gradient descent\n",
    "    weights_0_gradient = np.dot(layer_0.T, layer_1_delta)         # Weight1 = (First_feature_ex1 * Derivative_output_ex1) + (First_feature_ex2 * Derivative_output_ex2) + (First_feature_ex3 * Derivative_output_ex3) + ... \n",
    "                                                                  # Weight2 = (Second_feature_ex1 * Derivative_output_ex1) + (Second_feature_ex2 * Derivative_output_ex2) + (Second_feature_ex3 * Derivative_output_ex3) + ....\n",
    "                                                                  # (2x1)  \n",
    "    # Update weights\n",
    "    weights_0 = weights_0 - weights_0_gradient\n",
    "\n",
    "print (y)\n",
    "print (layer_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "[[ 0.00443338]\n",
      " [ 0.00443338]\n",
      " [ 0.9963659 ]\n",
      " [ 0.9963659 ]]\n"
     ]
    }
   ],
   "source": [
    "# 2 hidden layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "def sigmoid_to_derivative(output):\n",
    "    return output*(1 - output)\n",
    "\n",
    "# Create input\n",
    "X = np.array([[0,1],\n",
    "              [0,1],\n",
    "              [1,0],\n",
    "              [1,0]])\n",
    "\n",
    "# Create output\n",
    "Y = np.array([[0],\n",
    "              [0],\n",
    "              [1],\n",
    "              [1]])\n",
    "\n",
    "# Seed random\n",
    "np.random.seed(1)\n",
    "\n",
    "# Hidden layer size\n",
    "layer_1_size = 200\n",
    "layer_2_size = 100\n",
    "\n",
    "weights_0 = 2*np.random.random((2, layer_1_size)) -1\n",
    "weights_1 = 2*np.random.random((layer_1_size, layer_2_size)) - 1\n",
    "weights_2 = 2*np.random.random((layer_2_size, 1)) - 1\n",
    "\n",
    "for i in range(10000):\n",
    "    layer_0 = X\n",
    "    layer_1 = sigmoid(np.dot(layer_0, weights_0))\n",
    "    layer_2 = sigmoid(np.dot(layer_1, weights_1))\n",
    "    layer_3 = sigmoid(np.dot(layer_2, weights_2))\n",
    "\n",
    "    \n",
    "    # Error\n",
    "    layer_3_error = layer_3 - Y\n",
    "    layer_3_delta = layer_3_error * sigmoid_to_derivative(layer_3)\n",
    "    \n",
    "    # Error according to weights_2\n",
    "    layer_2_error = np.dot(layer_3_delta, weights_2.T)\n",
    "    layer_2_delta = layer_2_error * sigmoid_to_derivative(layer_2)\n",
    "    \n",
    "    # Error according to weights_1\n",
    "    layer_1_error = np.dot(layer_2_delta, weights_1.T)\n",
    "    layer_1_delta = layer_1_error * sigmoid_to_derivative(layer_1)\n",
    "    \n",
    "    # Gradient descent\n",
    "    weights_0_gradient = np.dot(layer_0.T, layer_1_delta)\n",
    "    \n",
    "    # Update weights_0\n",
    "    weights_0 = weights_0 - weights_0_gradient\n",
    "    \n",
    "print (Y)\n",
    "print (layer_3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00443318]\n",
      " [ 0.00443318]\n",
      " [ 0.99636607]\n",
      " [ 0.99636607]]\n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# 2 hidden layer\n",
    "# Make it like a class\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "def sigmoid_to_derivative(output):\n",
    "    return output * (1 - output)\n",
    "\n",
    "class Deep_Neural_Network:\n",
    "    def __init__(self):\n",
    "        self.layer_1_size = 200\n",
    "        self.layer_2_size = 100\n",
    "        self.weights_0 = 2*np.random.random((2, self.layer_1_size)) - 1\n",
    "        self.weights_1 = 2*np.random.random((self.layer_1_size, self.layer_2_size)) - 1\n",
    "        self.weights_2 = 2*np.random.random((self.layer_2_size, 1)) - 1\n",
    "        self.iteration = 10000\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        layer_0 = X\n",
    "        layer_1 = sigmoid(np.dot(layer_0, self.weights_0))\n",
    "        layer_2 = sigmoid(np.dot(layer_1, self.weights_1))\n",
    "        layer_3 = sigmoid(np.dot(layer_2, self.weights_2))\n",
    "        return layer_3\n",
    "    \n",
    "    def train(self, X, Y):\n",
    "        for i in range(self.iteration):\n",
    "            layer_0 = X\n",
    "            layer_1 = sigmoid(np.dot(layer_0, self.weights_0))\n",
    "            layer_2 = sigmoid(np.dot(layer_1, self.weights_1))\n",
    "            layer_3 = sigmoid(np.dot(layer_2, self.weights_2))\n",
    "        \n",
    "            # Error\n",
    "            layer_3_error = layer_3 - Y\n",
    "            layer_3_delta = layer_3_error * sigmoid_to_derivative(layer_3)\n",
    "        \n",
    "            # Back propagation - with respect to weights_2\n",
    "            layer_2_error = np.dot(layer_3_delta, self.weights_2.T)\n",
    "            layer_2_delta = layer_2_error * sigmoid_to_derivative(layer_2)\n",
    "            \n",
    "            # Back propagation - with respect to weights_1\n",
    "            layer_1_error = np.dot(layer_2_delta, self.weights_1.T)\n",
    "            layer_1_delta = layer_1_error * sigmoid_to_derivative(layer_1)\n",
    "            \n",
    "            # Gradient descent\n",
    "            weights_0_gradient = np.dot(layer_0.T, layer_1_delta)\n",
    "            \n",
    "            # Update weights_0\n",
    "            self.weights_0 = self.weights_0 - weights_0_gradient\n",
    "            \n",
    "neural_network = Deep_Neural_Network()\n",
    "\n",
    "# Create input\n",
    "X = np.array([[0,1],\n",
    "              [0,1],\n",
    "              [1,0],\n",
    "              [1,0]])\n",
    "\n",
    "# Create output\n",
    "Y = np.array([[0],\n",
    "              [0],\n",
    "              [1],\n",
    "              [1]])\n",
    "\n",
    "# Train the network\n",
    "neural_network.train(X,Y)\n",
    "\n",
    "\n",
    "print (neural_network.predict(X))\n",
    "print (Y)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
